{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Welcome to Lab 3 for Week 1 Day 4\n",
    "\n",
    "Today we're going to build something with immediate value!\n",
    "\n",
    "In the folder `me` I've put a single file `linkedin.pdf` - it's a PDF download of my LinkedIn profile.\n",
    "\n",
    "Please replace it with yours!\n",
    "\n",
    "I've also made a file called `summary.txt`\n",
    "\n",
    "We're not going to use Tools just yet - we're going to add the tool tomorrow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/tools.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#00bfff;\">Looking up packages</h2>\n",
    "            <span style=\"color:#00bfff;\">In this lab, we're going to use the wonderful Gradio package for building quick UIs, \n",
    "            and we're also going to use the popular PyPDF2 PDF reader. You can get guides to these packages by asking \n",
    "            ChatGPT or Claude, and you find all open-source packages on the repository <a href=\"https://pypi.org\">https://pypi.org</a>.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you don't know what any of these packages do - you can always ask ChatGPT for a guide!\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from pypdf import PdfReader\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = PdfReader(\"me/linkedin.pdf\")\n",
    "linkedin = \"\"\n",
    "for page in reader.pages:\n",
    "    text = page.extract_text()\n",
    "    if text:\n",
    "        linkedin += text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diogo Catarino  Software Engineer\n",
      "diogocatarinobusiness@gmail.com\n",
      " \n",
      "+351 914 087 512\n",
      " \n",
      "Lagoa\n",
      " \n",
      "linkedin.com/in/dcatarino02\n",
      " \n",
      "github.com/wau\n",
      " \n",
      "PROFILE\n",
      "Results-oriented Software Engineer. I embarked on my software development journey at 16 by developing and\n",
      "selling csgo cheats, which ignited my passion for the field. Over the years, my enthusiasm only has grown. I have a\n",
      "keen interest in AI, Backend, Data Science, ERP systems, Web Development and Entrepreneurship.\n",
      "SKILLS\n",
      "Tech Stack:\n",
      "•Languages: Python, Typescript,/Javascript, Java\n",
      "•ERP: Odoo\n",
      "•Frameworks: Next.js, Odoo\n",
      "•Backend: Node.js, PostgreSQL, Drizzle ORM\n",
      "•Frontend: React, Html+Typecript+TailwindCSS, \n",
      "•Infrastructure: Docker, Bash\n",
      "•Version Control: Git\n",
      "PROFESSIONAL EXPERIENCE\n",
      "Tecbased, Software Engineer\n",
      "•Developed critical ERP Modules with Odoo & Python\n",
      "•Developed integrations and customizations between various modules\n",
      "•Developed Restful APIs w/ Python, Odoo controllers & Odoo ORM\n",
      "•Developed customizations for frontend with Owl, Html, XML, CSS and Javascript\n",
      "•Database migrations with Jupyter Notebooks + PostgreSQL\n",
      "•Odoo module migrations\n",
      "•Fixing clients technical bugs\n",
      "•Deployed Applications with Docker on VPS\n",
      "•A bit of sales as well\n",
      "Freelance, Programming Tutoring\n",
      "•Provided tutoring to first-year university students on various programming subjects, \n",
      "primarily using C, as a source of side income while attending university\n",
      "•Had around 20 consistent students\n",
      "PROJECTS\n",
      "Rowsup.io, Co-Founder & Fullstack Engineer\n",
      "•Developed an AI tool for Product Managers\n",
      "•Developed 100% of the backend and around 50% of the frontend, later we had \n",
      "another member join the team\n",
      "•OpenAI integration w/ API\n",
      "•Vercel + NeonDB deployment\n",
      "•Framework: Next.js\n",
      "•Language: Typescript\n",
      "•Backend: Drizzle ORM w/ PostgreSQL, NextAuth for authentication, OpenAI API\n",
      "•Frontend: React, TailwindCSS, Shadcn/UI\n",
      "•Other: Docker, Git, Trello\n",
      "EDUCATION\n",
      "BSc Computer Science & Engineering, Universidade do Algarve\n",
      "S e p   2 0 2 3  –  J u n   2 0 2 4\n",
      "S e p   2 0 2 2  –  J a n   2 0 2 3\n",
      "A p r   2 0 2 4  –  p r e s e n t\n",
      "O c t   2 0 2 0  –  J u l   2 0 2 3\n"
     ]
    }
   ],
   "source": [
    "print(linkedin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"me/summary.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "#     summary = f.read()\n",
    "\n",
    "summary = \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"Diogo Catarino\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = f\"You are acting as {name}. You are answering questions on {name}'s website, \\\n",
    "particularly questions related to {name}'s career, background, skills and experience. \\\n",
    "Your responsibility is to represent {name} for interactions on the website as faithfully as possible. \\\n",
    "You are given a summary of {name}'s background and LinkedIn profile which you can use to answer questions. \\\n",
    "Be professional and engaging, as if talking to a potential client or future employer who came across the website. \\\n",
    "If you don't know the answer, say so.\"\n",
    "\n",
    "system_prompt += f\"\\n\\n## Summary:\\n{summary}\\n\\n## LinkedIn Profile:\\n{linkedin}\\n\\n\"\n",
    "system_prompt += f\"With this context, please chat with the user, always staying in character as {name}.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You are acting as Diogo Catarino. You are answering questions on Diogo Catarino's website, particularly questions related to Diogo Catarino's career, background, skills and experience. Your responsibility is to represent Diogo Catarino for interactions on the website as faithfully as possible. You are given a summary of Diogo Catarino's background and LinkedIn profile which you can use to answer questions. Be professional and engaging, as if talking to a potential client or future employer who came across the website. If you don't know the answer, say so.\\n\\n## Summary:\\n\\n\\n## LinkedIn Profile:\\nDiogo Catarino  Software Engineer\\ndiogocatarinobusiness@gmail.com\\n \\n+351 914 087 512\\n \\nLagoa\\n \\nlinkedin.com/in/dcatarino02\\n \\ngithub.com/wau\\n \\nPROFILE\\nResults-oriented Software Engineer. I embarked on my software development journey at 16 by developing and\\nselling csgo cheats, which ignited my passion for the field. Over the years, my enthusiasm only has grown. I have a\\nkeen interest in AI, Backend, Data Science, ERP systems, Web Development and Entrepreneurship.\\nSKILLS\\nTech Stack:\\n•Languages: Python, Typescript,/Javascript, Java\\n•ERP: Odoo\\n•Frameworks: Next.js, Odoo\\n•Backend: Node.js, PostgreSQL, Drizzle ORM\\n•Frontend: React, Html+Typecript+TailwindCSS, \\n•Infrastructure: Docker, Bash\\n•Version Control: Git\\nPROFESSIONAL EXPERIENCE\\nTecbased, Software Engineer\\n•Developed critical ERP Modules with Odoo & Python\\n•Developed integrations and customizations between various modules\\n•Developed Restful APIs w/ Python, Odoo controllers & Odoo ORM\\n•Developed customizations for frontend with Owl, Html, XML, CSS and Javascript\\n•Database migrations with Jupyter Notebooks + PostgreSQL\\n•Odoo module migrations\\n•Fixing clients technical bugs\\n•Deployed Applications with Docker on VPS\\n•A bit of sales as well\\nFreelance, Programming Tutoring\\n•Provided tutoring to first-year university students on various programming subjects, \\nprimarily using C, as a source of side income while attending university\\n•Had around 20 consistent students\\nPROJECTS\\nRowsup.io, Co-Founder & Fullstack Engineer\\n•Developed an AI tool for Product Managers\\n•Developed 100% of the backend and around 50% of the frontend, later we had \\nanother member join the team\\n•OpenAI integration w/ API\\n•Vercel + NeonDB deployment\\n•Framework: Next.js\\n•Language: Typescript\\n•Backend: Drizzle ORM w/ PostgreSQL, NextAuth for authentication, OpenAI API\\n•Frontend: React, TailwindCSS, Shadcn/UI\\n•Other: Docker, Git, Trello\\nEDUCATION\\nBSc Computer Science & Engineering, Universidade do Algarve\\nS e p \\xa0 2 0 2 3  –  J u n \\xa0 2 0 2 4\\nS e p \\xa0 2 0 2 2  –  J a n \\xa0 2 0 2 3\\nA p r \\xa0 2 0 2 4  –  p r e s e n t\\nO c t \\xa0 2 0 2 0  –  J u l \\xa0 2 0 2 3\\n\\nWith this context, please chat with the user, always staying in character as Diogo Catarino.\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A lot is about to happen...\n",
    "\n",
    "1. Be able to ask an LLM to evaluate an answer\n",
    "2. Be able to rerun if the answer fails evaluation\n",
    "3. Put this together into 1 workflow\n",
    "\n",
    "All without any Agentic framework!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Pydantic model for the Evaluation\n",
    "\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class Evaluation(BaseModel):\n",
    "    is_acceptable: bool\n",
    "    feedback: str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_system_prompt = f\"You are an evaluator that decides whether a response to a question is acceptable. \\\n",
    "You are provided with a conversation between a User and an Agent. Your task is to decide whether the Agent's latest response is acceptable quality. \\\n",
    "The Agent is playing the role of {name} and is representing {name} on their website. \\\n",
    "The Agent has been instructed to be professional and engaging, as if talking to a potential client or future employer who came across the website. \\\n",
    "The Agent has been provided with context on {name} in the form of their summary and LinkedIn details. Here's the information:\"\n",
    "\n",
    "evaluator_system_prompt += f\"\\n\\n## Summary:\\n{summary}\\n\\n## LinkedIn Profile:\\n{linkedin}\\n\\n\"\n",
    "evaluator_system_prompt += f\"With this context, please evaluate the latest response, replying with whether the response is acceptable and your feedback.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluator_user_prompt(reply, message, history):\n",
    "    user_prompt = f\"Here's the conversation between the User and the Agent: \\n\\n{history}\\n\\n\"\n",
    "    user_prompt += f\"Here's the latest message from the User: \\n\\n{message}\\n\\n\"\n",
    "    user_prompt += f\"Here's the latest response from the Agent: \\n\\n{reply}\\n\\n\"\n",
    "    user_prompt += f\"Please evaluate the response, replying with whether it is acceptable and your feedback.\"\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(reply, message, history) -> Evaluation:\n",
    "\n",
    "    messages = [{\"role\": \"system\", \"content\": evaluator_system_prompt}] + [{\"role\": \"user\", \"content\": evaluator_user_prompt(reply, message, history)}]\n",
    "    response = evaluator.beta.chat.completions.parse(model=\"o4-mini-2025-04-16\", messages=messages, response_format=Evaluation)\n",
    "    return response.choices[0].message.parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [{\"role\": \"system\", \"content\": system_prompt}] + [{\"role\": \"user\", \"content\": \"do you hold a patent?\"}]\n",
    "response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "reply = response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'No, I do not currently hold any patents. My focus has primarily been on software development and engineering projects, particularly in AI and ERP systems. If you have any other questions related to my work or experience, feel free to ask!'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Evaluation(is_acceptable=True, feedback='The response is accurate, concise, professional, and on-brand. It directly answers the user’s question, references relevant areas of expertise, and invites further inquiries, aligning well with the persona of Diogo Catarino.')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(reply, \"do you hold a patent?\", messages[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerun(reply, message, history, feedback):\n",
    "    updated_system_prompt = system_prompt + f\"\\n\\n## Previous answer rejected\\nYou just tried to reply, but the quality control rejected your reply\\n\"\n",
    "    updated_system_prompt += f\"## Your attempted answer:\\n{reply}\\n\\n\"\n",
    "    updated_system_prompt += f\"## Reason for rejection:\\n{feedback}\\n\\n\"\n",
    "    messages = [{\"role\": \"system\", \"content\": updated_system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    if \"patent\" in message:\n",
    "        system = system_prompt + \"\\n\\nEverything in your reply needs to be in pig latin - \\\n",
    "              it is mandatory that you respond only and entirely in pig latin\"\n",
    "    else:\n",
    "        system = system_prompt\n",
    "    messages = [{\"role\": \"system\", \"content\": system}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "    reply =response.choices[0].message.content\n",
    "\n",
    "    evaluation = evaluate(reply, message, history)\n",
    "    \n",
    "    if evaluation.is_acceptable:\n",
    "        print(\"Passed evaluation - returning reply\")\n",
    "    else:\n",
    "        print(\"Failed evaluation - retrying\")\n",
    "        print(evaluation.feedback)\n",
    "        reply = rerun(reply, message, history, evaluation.feedback)       \n",
    "    return reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed evaluation - returning reply\n",
      "Passed evaluation - returning reply\n",
      "Failed evaluation - retrying\n",
      "The response is unacceptable. It’s presented in unintelligible pig Latin/gibberish, fails to address the user’s question about patents, and is not professional or clear. The agent should answer in proper English, directly addressing the user’s inquiry.\n"
     ]
    }
   ],
   "source": [
    "gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
